# Описание задания

## Формулировка задания

В этом практическом задании вы примените разработанные ранее пайплайны предварительной обработки данных (из ПЗ №2) для обучения **моделей машинного обучения на основе деревьев решений и их ансамблей**.

Цель работы — познакомиться с мощными и широко применяемыми на практике алгоритмами, научиться использовать `scikit-learn` и другие библиотеки для их построения и оценки, а также сформировать понимание сильных и слабых сторон разных подходов к решению задач обучения с учителем.

---

## Постановка задачи

1. **Подключите и примените пайплайн предобработки данных из ПЗ №2.**
   - Можно загрузить готовый пайплайн при помощи `joblib` (см. [документацию](https://scikit-learn.org/stable/model_persistence.html)) или просто перенести код.
   - Пайплайн должен преобразовывать «сырые» данные в числовую матрицу признаков, пригодную для обучения моделей.

2. **Обучите готовые модели из `scikit-learn` и других библиотек.**
   Рекомендуемые реализации:
   - Для **регрессии**:
     - `DecisionTreeRegressor()` — решающее дерево для регрессии;
     - `RandomForestRegressor()` — случайный лес;
     - `GradientBoostingRegressor()` — градиентный бустинг от scikit-learn;
     - `HistGradientBoostingRegressor()` — более быстрая реализация градиентного бустинга;
     - Модели из библиотеки `XGBoost` (`XGBRegressor`) и/или `LightGBM` (`LGBMRegressor`).
   - Для **классификации**:
     - `DecisionTreeClassifier()` — решающее дерево для классификации;
     - `RandomForestClassifier()` — случайный лес;
     - `GradientBoostingClassifier()` — градиентный бустинг от scikit-learn;
     - `HistGradientBoostingClassifier()` — более быстрая реализация градиентного бустинга;
     - Модели из библиотеки `XGBoost` (`XGBClassifier`) и/или `LightGBM` (`LGBMClassifier`).

   Обучите несколько моделей, изменяя ключевые гиперпараметры (например, `max_depth`, `n_estimators`, `learning_rate`), и сравните результаты.

3. **Проведите серию экспериментов.**
   - Для каждой модели сохраните результаты обучения в общую таблицу экспериментов (предпочтительно Google Sheet), **дополнив таблицу из предыдущего задания**.
   - Для регрессии используйте метрики `MAE`, `RMSE`, `R2`.
   - Для классификации — `Accuracy`, `Precision`, `Recall`, `F1`.
   - Сделайте развернутые выводы: какая модель и с какими гиперпараметрами работает лучше, как ведут себя разные типы моделей (деревья vs бэггинг vs бустинг), как их результаты сравниваются с линейными моделями из предыдущей работы.

---

## Критерии оценивания

### Обязательные условия
- Решение представлено в блокноте `solution.ipynb`;
- Блокнот имеет аккуратный вид (заголовки, пояснения, отсутствие лишнего кода и ошибок выполнения);
- Предобработка данных осуществляется с помощью пайплайна из ПЗ №2;
- Результаты экспериментов сведены в таблицу (очень предпочтительно Google Sheet), объединяющую результаты линейных и древовидных моделей;
- Отсутствует недобросовестное использование LLM.

Работа, не соответствующая этим условиям, оценивается в 0 баллов. Допускается одна попытка исправления.

---

### Начисление баллов

1. **Использование пайплайна предобработки данных** — 2 балла.  
   Пайплайн корректно применён для обучения моделей, не содержит ручных операций вне `sklearn`.

2. **Обучение моделей регрессии на основе деревьев** — 2 балла.  
   Проведено обучение и оценка не менее трёх моделей (например, `DecisionTreeRegressor`, `RandomForestRegressor` и одна из реализаций градиентного бустинга). Результаты сохранены в таблицу.

3. **Обучение моделей классификации на основе деревьев** — 2 балла.  
   Проведено обучение и оценка не менее трёх моделей (например, `DecisionTreeClassifier`, `RandomForestClassifier` и одна из реализаций градиентного бустинга). Результаты сохранены в таблицу.

4. **Сравнение и углубленный анализ экспериментов** — 4 балла.  
   Метрики всех моделей (линейных и древовидных) рассчитаны и сведены в единую таблицу. Даны развернутые, осмысленные выводы, сравнивающие производительность, склонность к переобучению, скорость работы и применимость разных семейств алгоритмов на вашем наборе данных.

---

### Снятие баллов
- за выполнение предобработки вне пайплайна;
- за неполные результаты экспериментов (отсутствие результатов за предыдущие или текущие модели);
- за неполную или ошибочную реализацию любого шага (обучение моделей, анализ);
- за поверхностный анализ без сравнения семейств алгоритмов.